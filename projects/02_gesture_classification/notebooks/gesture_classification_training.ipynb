{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__x7XzFAbo8j"
      },
      "source": [
        "# Gesture Classification\n",
        "\n",
        "Welcome to the IMU gesture classification training script! This was designed to run in Google Colab, but it should (in theory) run in any Jupyter Notebook or Jupyter Lab environment with PyTorch installed.\n",
        "\n",
        "In Google Colab, select **File > Open notebook** then select the **Upload** tab. Select this file to open it in Colab.\n",
        "\n",
        "Press **shift + enter** to execute each cell in order. Make sure you stop and read each text section, as there are some manual steps you will need to perform (e.g. upload dataset)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjzQWq7xbUvP"
      },
      "outputs": [],
      "source": [
        "# Install specific versions of the packages\n",
        "!python3 -m pip install \\\n",
        "    matplotlib=='3.10.0' \\\n",
        "    numpy=='2.0.2' \\\n",
        "    onnxscript=='0.5.7' \\\n",
        "    pandas=='2.2.2' \\\n",
        "    torch=='2.9.0+cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JcZ35GGPceXw"
      },
      "outputs": [],
      "source": [
        "# Import standard libraries\n",
        "import os\n",
        "from pathlib import Path\n",
        "import random\n",
        "import zipfile\n",
        "\n",
        "# Import third-party libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRXLkoogcuJw"
      },
      "outputs": [],
      "source": [
        "# Print out the versions of the libraries\n",
        "print(f\"Matplotlib version: {plt.matplotlib.__version__}\")\n",
        "print(f\"NumPy version: {np.__version__}\")\n",
        "print(f\"Pandas version: {pd.__version__}\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "km8XQ2uucvru"
      },
      "outputs": [],
      "source": [
        "# General settings\n",
        "SEED = 42\n",
        "GESTURES_ZIP_PATH = Path(\"/content/01_imu_gestures.zip\")\n",
        "GESTURE_DATASET_PATH = Path(\"/content/imu_gestures\")\n",
        "COL_NAME_TIMESTAMP = \"timestamp\"\n",
        "\n",
        "# Data settings\n",
        "VAL_SPLIT = 0.2\n",
        "TEST_SPLIT = 0.2\n",
        "\n",
        "# Model settings\n",
        "HIDDEN_1_SIZE = 64\n",
        "HIDDEN_2_SIZE = 32\n",
        "DROPOUT = 0.3\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 0.001\n",
        "NUM_EPOCHS = 50\n",
        "\n",
        "# ONNX export settings\n",
        "ONNX_OPSET_VERSION = 18\n",
        "ONNX_PATH = Path(\"/content/model.onnx\")\n",
        "\n",
        "# Calibration data settings\n",
        "NUM_CALIB_SAMPLES = 100\n",
        "CALIB_NPZ_PATH = Path(\"/content/calibration_data.npz\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5NtA_FT-i71p"
      },
      "outputs": [],
      "source": [
        "# Set random seeds for reproducibility\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the target compute device (GPU or CPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "lg7ofEkA3ly5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaJ_6A1SdiP3"
      },
      "source": [
        "## Prepare Dataset\n",
        "\n",
        "You will need to manually upload the gesture dataset you created. This should include at least 100 samples (each sample in its own CSV file) for each of the 5 classes (_idle, _other, alpha, beta, gamma).\n",
        "\n",
        "First, zip your dataset as follows:\n",
        "\n",
        "```\n",
        "01_imu_gestures.zip\n",
        "├─ _idle/\n",
        "│  ├─ 000000.CSV\n",
        "│  ├─ 000001.CSV\n",
        "│  └─ ...\n",
        "├─ _other/\n",
        "│  ├─ 000000.CSV\n",
        "│  ├─ 000001.CSV\n",
        "│  └─ ...\n",
        "├─ alpha/\n",
        "│  ├─ 000000.CSV\n",
        "│  ├─ 000001.CSV\n",
        "│  └─ ...\n",
        "├─ beta/\n",
        "│  ├─ 000000.CSV\n",
        "│  ├─ 000001.CSV\n",
        "│  └─ ...\n",
        "└─ gamma/\n",
        "   ├─ 000000.CSV\n",
        "   ├─ 000001.CSV\n",
        "   └─ ...\n",
        "```\n",
        "\n",
        "On the left side, click the **Folder** icon to expand the file browser tab. Click the **Upload** icon. Select the **01_imu_gestures.zip** file to upload it to this Colab instance.\n",
        "\n",
        "Once you have uploaded the .zip file, run the following cells to unzip and prepare the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Km-zEYCIdhW8"
      },
      "outputs": [],
      "source": [
        "# Extract the zip file\n",
        "with zipfile.ZipFile(GESTURES_ZIP_PATH, 'r') as zip_ref:\n",
        "    zip_ref.extractall(GESTURE_DATASET_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LznpNJtPjr_Q"
      },
      "outputs": [],
      "source": [
        "# Discover class names based on folder names\n",
        "class_names = sorted([d for d in os.listdir(GESTURE_DATASET_PATH)\n",
        "                      if os.path.isdir(os.path.join(GESTURE_DATASET_PATH, d))])\n",
        "print(f\"Class names: {class_names}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "080fpje7kC3B"
      },
      "outputs": [],
      "source": [
        "# Map an index number to each class name\n",
        "class_to_idx = {class_name: idx for idx, class_name in enumerate(class_names)}\n",
        "print(class_to_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxib1poakU5j"
      },
      "outputs": [],
      "source": [
        "# Store data, labels, and channel (column) names\n",
        "all_data = []\n",
        "all_labels = []\n",
        "channel_names = None\n",
        "\n",
        "# Go through each directory\n",
        "first_file = True\n",
        "for class_name in class_names:\n",
        "\n",
        "    # Construct path to data in a given class\n",
        "    class_folder = GESTURE_DATASET_PATH / class_name\n",
        "    csv_files = sorted(os.listdir(class_folder))\n",
        "\n",
        "    # Read all CSV files\n",
        "    for csv_file in csv_files:\n",
        "        if csv_file.endswith('.CSV'):\n",
        "            csv_path = class_folder / csv_file\n",
        "\n",
        "            # Read CSV file\n",
        "            df = pd.read_csv(csv_path)\n",
        "\n",
        "            # Extract channel (column) names\n",
        "            if first_file:\n",
        "                channel_names = df.columns.tolist()\n",
        "                first_file = False\n",
        "\n",
        "                # Remove timestamp column name\n",
        "                channel_names = [c for c in df.columns if c != COL_NAME_TIMESTAMP]\n",
        "\n",
        "            # Extract the 6 IMU values (3-axis accel and gyro)\n",
        "            sensor_data = df[channel_names].values\n",
        "\n",
        "            # Append sample and class index to lists\n",
        "            all_data.append(sensor_data)\n",
        "            all_labels.append(class_to_idx[class_name])\n",
        "\n",
        "# Get the total number of samples loaded\n",
        "num_samples = len(all_data)\n",
        "print(f\"Loaded {num_samples} total samples\")\n",
        "print(f\"Channels: {channel_names}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymlQI-iSmKUq"
      },
      "outputs": [],
      "source": [
        "# Pair each sample with its associated label\n",
        "data_label_pairs = list(zip(all_data, all_labels))\n",
        "\n",
        "# Shuffle the pairs randomly\n",
        "random.shuffle(data_label_pairs)\n",
        "\n",
        "# Unzip back into separate lists\n",
        "shuffled_data, shuffled_labels = zip(*data_label_pairs)\n",
        "shuffled_data = list(shuffled_data)\n",
        "shuffled_labels = list(shuffled_labels)\n",
        "\n",
        "# Calculate split indices\n",
        "test_end_idx = int(TEST_SPLIT * num_samples)\n",
        "val_end_idx = int((VAL_SPLIT + TEST_SPLIT) * num_samples)\n",
        "\n",
        "print(f\"Test end index: {test_end_idx}\")\n",
        "print(f\"Validation end index: {val_end_idx}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxa4p0sbnkY8"
      },
      "outputs": [],
      "source": [
        "# The first section of shuffled samples becomes the test set\n",
        "test_data = shuffled_data[:test_end_idx]\n",
        "test_labels = shuffled_labels[:test_end_idx]\n",
        "\n",
        "# The second section of shuffled samples becomes the validation set\n",
        "val_data = shuffled_data[test_end_idx:val_end_idx]\n",
        "val_labels = shuffled_labels[test_end_idx:val_end_idx]\n",
        "\n",
        "# The third section of shuffled samples becomes the training set\n",
        "train_data = shuffled_data[val_end_idx:]\n",
        "train_labels = shuffled_labels[val_end_idx:]\n",
        "\n",
        "print(f\"Training set size: {len(train_data)}\")\n",
        "print(f\"Validation set size: {len(val_data)}\")\n",
        "print(f\"Test set size: {len(test_data)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Examine Data\n",
        "\n",
        "In most machine learning projects, you will want to examine your data. Look for trends or other interesting features that can help you build a model. Sometimes, you might find that you don't need machine learning after all!\n",
        "\n",
        "For our case, we're going to look at the basic statistics of the training set and plot one of the samples (so you can see what it looks like).\n",
        "\n",
        "You'll also want to look for bad or missing data. Sometimes, you'll have to remove bad samples or supplement the data. Our ML model will expect a very specific number of values as input and will break if our data does not match that matrix shape!"
      ],
      "metadata": {
        "id": "AV2IccxXQ5Bn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ZtMPltwqq52"
      },
      "outputs": [],
      "source": [
        "# Ensure all the samples have the same length\n",
        "sample_lengths = [data.shape[0] for data in train_data]\n",
        "min_len = min(sample_lengths)\n",
        "max_len = max(sample_lengths)\n",
        "\n",
        "# Check the sample lengths\n",
        "print(f\"Minimum sample length: {min_len}\")\n",
        "print(f\"Maximum sample length: {max_len}\")\n",
        "if min_len != max_len:\n",
        "    print(\"Warning: Samples have different lengths!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate all training samples\n",
        "train_data_concat = np.concatenate(train_data, axis=0)\n",
        "\n",
        "# Store mean and standard deviation for each sensor channel\n",
        "means = []\n",
        "stds = []\n",
        "\n",
        "# Calculate statistics\n",
        "for i, channel in enumerate(channel_names):\n",
        "    mean = np.mean(train_data_concat[:, i])\n",
        "    std = np.std(train_data_concat[:, i])\n",
        "    means.append(mean)\n",
        "    stds.append(std)\n",
        "\n",
        "# Print statistics\n",
        "for i, channel in enumerate(channel_names):\n",
        "    print(f\"Channel: {channel}\")\n",
        "    print(f\"  Mean: {means[i]:.2f}\")\n",
        "    print(f\"  Std dev: {stds[i]:.2f}\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "YOOFmBoOR1qg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a sample\n",
        "def plot_sample(data):\n",
        "    \"\"\"\n",
        "    Plot a sample\n",
        "    \"\"\"\n",
        "    # Create a figure with 2 subplots (one for accel, one for gyro)\n",
        "    fig, axes = plt.subplots(2, 1, figsize=(12, 8))\n",
        "\n",
        "    # Plot accelerometer data\n",
        "    axes[0].plot(data[:, 0], label=\"accel_x\", color='red')\n",
        "    axes[0].plot(data[:, 1], label=\"accel_y\", color='green')\n",
        "    axes[0].plot(data[:, 2], label=\"accel_z\", color='blue')\n",
        "    axes[0].set_xlabel(\"Timestep\")\n",
        "    axes[0].set_ylabel(\"Acceleration (raw)\")\n",
        "    axes[0].set_title(\"3-Axis Accelerometer Data\")\n",
        "    axes[0].legend(loc='upper right')\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Plot gyroscope data\n",
        "    axes[1].plot(data[:, 3], label=\"gyro_x\", color='red')\n",
        "    axes[1].plot(data[:, 4], label=\"gyro_y\", color='green')\n",
        "    axes[1].plot(data[:, 5], label=\"gyro_z\", color='blue')\n",
        "    axes[1].set_xlabel(\"Timestep\")\n",
        "    axes[1].set_ylabel(\"Angular Velocity (raw)\")\n",
        "    axes[1].set_title(\"3-Axis Gyroscope Data\")\n",
        "    axes[1].legend(loc='upper right')\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "    # Show plots\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "vAW110fOnazP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a sample (by index) in the training set\n",
        "idx = 0\n",
        "\n",
        "# Plot sample\n",
        "label = train_labels[idx]\n",
        "print(f\"Label: {label} (Class: {class_names[label]})\")\n",
        "plot_sample(train_data[idx])"
      ],
      "metadata": {
        "id": "8GAg3pK2Uir1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the number of times each label appears in the training set\n",
        "train_label_counts = np.bincount(train_labels)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars = plt.bar(class_names, train_label_counts, color='lightblue')\n",
        "plt.xlabel(\"Gesture Class\")\n",
        "plt.ylabel(\"Number of Samples\")\n",
        "plt.title(\"Training Set Class Distribution\")\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Show plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-U_7tcbxVnAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a Custom Dataset\n",
        "\n",
        "PyTorch has a particular way it likes to retrieve samples during training and testing a model. It wants to get items from a custom subclass of the `Dataset` class.\n",
        "\n",
        "We will accomplish this in two distinct steps:\n",
        "\n",
        " 1. Normalize all data\n",
        " 2. Wrap that normalized data in a custom `IMUGestureDataset` class\n",
        "\n",
        "Neural networks learn better (i.e. converge faster and more reliably) when all the input features are on similar scales. Without normalization/standardization, sensors with large raw values (e.g. like our accelerometers readings of ~2000) would dominate the learning process over smaller values (e.g. our gyroscope readings of ~50). This type of scaling ensures every sensor contributes fairly to the model's predictions.\n",
        "\n",
        "Some definitions:\n",
        " * **Normalization** - Scale all data to a fixed range (usually between 0 and 1)\n",
        " * **Standardization** - Scale all data to have a mean of 0 and a standard deviation of 1 (we will use this approach)\n",
        "\n",
        " We normalize or standardize the data once before creating the `Dataset` (rather than inside it) so that we only have to perform this operation once instead of repeating every time we retrieve a sample during training."
      ],
      "metadata": {
        "id": "cSBDYCHIfkhZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def standardize_data(data_list, mean, std):\n",
        "    \"\"\"\n",
        "    Standardize data using: (x - mean) / std\n",
        "    \"\"\"\n",
        "    standardize_data = []\n",
        "\n",
        "    # Ensure we have no divide-by-zero errors (just center the data)\n",
        "    std_safe = np.where(std == 0.0, 1.0, std)\n",
        "\n",
        "    # Apply normalization: (data - mean) / std for all channels\n",
        "    for data in data_list:\n",
        "        scaled_data = (data - mean) / std_safe\n",
        "        standardize_data.append(scaled_data)\n",
        "\n",
        "    return standardize_data"
      ],
      "metadata": {
        "id": "HY8-UdY6WoMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize all datasets using training statistics\n",
        "train_data_standardized = standardize_data(train_data, means, stds)\n",
        "val_data_standardized = standardize_data(val_data, means, stds)\n",
        "test_data_standardized = standardize_data(test_data, means, stds)"
      ],
      "metadata": {
        "id": "WgoZIfZLjwtw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a sample (by index) in the training set\n",
        "idx = 0\n",
        "\n",
        "# Plot standardized sample (notice the DC offset is removed!)\n",
        "label = train_labels[idx]\n",
        "print(f\"Label: {label} (Class: {class_names[label]})\")\n",
        "plot_sample(train_data_standardized[idx])"
      ],
      "metadata": {
        "id": "C4sFyYVprkjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class IMUGestureDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Custom PyTorch Dataset for IMU gesture data.\n",
        "    \"\"\"\n",
        "    def __init__(self, data_list, labels_list):\n",
        "        \"\"\"\n",
        "        Initialize the dataset\n",
        "        \"\"\"\n",
        "        self.data = data_list\n",
        "        self.labels = labels_list\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Returns the length of the dataset\n",
        "        \"\"\"\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Returns one sample at index idx (as Pytorch tensors)\n",
        "        \"\"\"\n",
        "        # Get the sample and flatten it from (timesteps, sensors) to 1D vector\n",
        "        sample = self.data[idx]  # Shape: (timesteps, num_sensors)\n",
        "        sample_flat = sample.flatten()  # Shape: (timesteps * num_sensors,)\n",
        "\n",
        "        # Convert to PyTorch tensors\n",
        "        x = torch.FloatTensor(sample_flat)\n",
        "        y = torch.LongTensor([self.labels[idx]])[0]\n",
        "\n",
        "        return x, y"
      ],
      "metadata": {
        "id": "svhUh0dgnSN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wrap each standardized dataset in a custom Dataset object\n",
        "train_dataset = IMUGestureDataset(train_data_standardized, train_labels)\n",
        "val_dataset = IMUGestureDataset(val_data_standardized, val_labels)\n",
        "test_dataset = IMUGestureDataset(test_data_standardized, test_labels)"
      ],
      "metadata": {
        "id": "PHrUvrScqmS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a single sample from the training dataset\n",
        "idx = 0\n",
        "x, y = train_dataset[idx]\n",
        "\n",
        "# Print some info\n",
        "print(f\"Original shape of data: {train_data[idx].shape}\")\n",
        "print(f\"New shape of data: {x.shape}\")\n",
        "print(f\"Label: {y} (Class: {class_names[y]})\")\n"
      ],
      "metadata": {
        "id": "uBoNRxmHrDhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create DataLoaders\n",
        "\n",
        "A `DataLoader` takes individual samples from a `Dataset` and groups them into batches (e.g. 32 samples at a time), which allows the model to process multiple samples simultaneously for efficient training. We especially see speedup gains when we move to training on GPUs and accelerators, which are highly optimized for parallel computation.\n",
        "\n",
        "The `DataLoader` also handles shuffling the training data between epochs (to prevent the model from learning patterns based on sample order) and automatically manages edge cases like partial batches at the end of the dataset."
      ],
      "metadata": {
        "id": "2OTfgp41sOEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataLoader for each of our splits\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ],
      "metadata": {
        "id": "rriyJyxArejH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Demonstrate how to get one batch from the training DataLoader\n",
        "sample_batch_x, sample_batch_y = next(iter(train_loader))\n",
        "\n",
        "# Print the shapes\n",
        "print(f\"Shape of batch: {sample_batch_x.shape}\")\n",
        "print(f\"Shape of labels: {sample_batch_y.shape}\")"
      ],
      "metadata": {
        "id": "hPS7qR8TtIoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build Machine Learning Model\n",
        "\n",
        "We're going to build a simple 2-layer dense neural network (fully connected layers).\n",
        "\n",
        "Understanding how to build a model architecture takes time and experience. In many ways, it's the \"art\" side of machine learning. I settled on 2 layers because (after some tinkering) I discovered that 1 layer did not learn the gestures well and 3 layers started overfitting.\n",
        "\n",
        "You'll see many applications of the \"funnel\" or \"encoder\" pattern where deeper layers have fewer nodes than previous layers. Earlier layers derive low-level features from the data (e.g. acceleration spikes, smooth rotations, oscillations) whereas later layers combine these features into high-level concepts (e.g. \"flick\" or \"circle\").\n",
        "\n",
        "The final layer is composed of the same number of nodes as we have classes. The output of these nodes are the raw prediction values that provide a score (known as a \"logit\") of how strongly the model thinks the input data belongs to a particular class.\n",
        "\n",
        "We can feed these logits into a softmax function to scale them between 0 and 1 as well as ensure that they sum to 1. This gives us something like a \"probability score\" for how closely the model believes the input data belongs to a particular class. Note that the `CrossEntropyLoss` function handles the softmax for us, so we don't explicitly add it to the model."
      ],
      "metadata": {
        "id": "UQH0eMBotqBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleDNN(nn.Module):\n",
        "    \"\"\"\n",
        "    Simple 2-layer Deep Neural Network\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_size,\n",
        "        hidden_1_size,\n",
        "        hidden_2_size,\n",
        "        num_classes,\n",
        "        dropout\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Constructor that defines the NN layers.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        # Hidden layer 1\n",
        "        self.fc1 = nn.Linear(input_size, hidden_1_size)\n",
        "        self.relu1 = nn.ReLU()\n",
        "\n",
        "        # Randomly disable some outputs of fc1 neurons\n",
        "        # This can help with overfitting\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "\n",
        "        # Hidden layer 2\n",
        "        self.fc2 = nn.Linear(hidden_1_size, hidden_2_size)\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "        # Randomly disable some outputs of fc2 neurons\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "        # Output Layer\n",
        "        self.fc3 = nn.Linear(hidden_2_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Defines how data flows through the model\n",
        "        \"\"\"\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "Rsz1ZtwAtiTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the input shape of a single sample\n",
        "x, _ = train_dataset[0]\n",
        "input_size = x.shape[0]\n",
        "\n",
        "# Initialize the model\n",
        "model = SimpleDNN(\n",
        "    input_size=input_size,\n",
        "    hidden_1_size=HIDDEN_1_SIZE,\n",
        "    hidden_2_size=HIDDEN_2_SIZE,\n",
        "    num_classes=len(class_names),\n",
        "    dropout=DROPOUT\n",
        ")\n",
        "\n",
        "# Print model details\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters()\n",
        "                        if p.requires_grad)\n",
        "print(model)\n",
        "print(f\"Total parameters: {total_params}\")\n",
        "print(f\"Trainable parameters: {trainable_params}\")"
      ],
      "metadata": {
        "id": "s-Ap-68v0U3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure model and data are on same device (CPU or GPU)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "tPFhdEPq4waG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function (measure how wrong the model's predictions are)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer (how to adjust the model's weights to reduce loss)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
      ],
      "metadata": {
        "id": "Lccg4g1R1AuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training\n",
        "\n",
        "Training is split into two sections. In the first part, we run a forward pass using one batch of data, calculate the loss, perform a backward pass to calculate the gradients, and then update the model's weights. We repeat this for all the data in the training dataset (one epoch). In the second part, we use the validation data to see how well the model is performing for that epoch.\n",
        "\n",
        "We repeat these training and validation processes for as many epochs as we defined. We then plot the training and validation loss over time to see how well the model performed at the task of predicting the correct classes."
      ],
      "metadata": {
        "id": "835rf10U5xlg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(\n",
        "    model,\n",
        "    dataloader,\n",
        "    loss_fn,\n",
        "    optimizer,\n",
        "    device\n",
        "):\n",
        "    \"\"\"\n",
        "    Train the model for one epoch\n",
        "    \"\"\"\n",
        "    total_loss = 0.0\n",
        "    num_correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    # Enable training-specific behaviors (e.g. dropout)\n",
        "    model.train()\n",
        "\n",
        "    # Do one full training cycle on a batch of training data\n",
        "    for batch_x, batch_y in dataloader:\n",
        "        # Move data to the same device as the model\n",
        "        batch_x = batch_x.to(device)\n",
        "        batch_y = batch_y.to(device)\n",
        "\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(batch_x)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = loss_fn(outputs, batch_y)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Update weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # Get total loss for the batch (loss.item() is the average)\n",
        "        total_loss += loss.item() * batch_x.size(0)\n",
        "        total_samples += batch_y.size(0)\n",
        "\n",
        "        # Count how many predictions matched the true labels\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        num_correct += (predicted == batch_y).sum().item()\n",
        "\n",
        "    # Calculate averages\n",
        "    avg_loss = total_loss / total_samples\n",
        "    accuracy = num_correct / total_samples\n",
        "\n",
        "    return avg_loss, accuracy"
      ],
      "metadata": {
        "id": "9pzztjbI3eCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(model, dataloader, loss_fn, device):\n",
        "    \"\"\"\n",
        "    Compute the loss and accuracy on a given dataset\n",
        "    \"\"\"\n",
        "    total_loss = 0.0\n",
        "    num_correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    # Disable training-specific behaviors (e.g. dropout)\n",
        "    model.eval()\n",
        "\n",
        "    # Do not track gradients during validation\n",
        "    with torch.no_grad():\n",
        "        for batch_x, batch_y in dataloader:\n",
        "            # Move data to the same device as the model\n",
        "            batch_x = batch_x.to(device)\n",
        "            batch_y = batch_y.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(batch_x)\n",
        "\n",
        "            # Calculate loss\n",
        "            loss = loss_fn(outputs, batch_y)\n",
        "\n",
        "            # Get total loss for the batch (loss.item() is the average)\n",
        "            total_loss += loss.item() * batch_x.size(0)\n",
        "            total_samples += batch_y.size(0)\n",
        "\n",
        "            # Count how many predictions matched the true labels\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            num_correct += (predicted == batch_y).sum().item()\n",
        "\n",
        "    # Calculate averages\n",
        "    avg_loss = total_loss / total_samples\n",
        "    accuracy = num_correct / total_samples\n",
        "\n",
        "    return avg_loss, accuracy"
      ],
      "metadata": {
        "id": "MXiyEaxs91h3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lists to store metrics for plotting later\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "\n",
        "    # Train for one epoch\n",
        "    train_loss, train_acc = train_one_epoch(\n",
        "        model,\n",
        "        train_loader,\n",
        "        loss_fn,\n",
        "        optimizer,\n",
        "        device\n",
        "    )\n",
        "\n",
        "    # Validate\n",
        "    val_loss, val_acc = validate(\n",
        "        model,\n",
        "        val_loader,\n",
        "        loss_fn,\n",
        "        device\n",
        "    )\n",
        "\n",
        "    # Store metrics\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "    train_accuracies.append(train_acc)\n",
        "    val_accuracies.append(val_acc)\n",
        "\n",
        "    # Print progress\n",
        "    print(f\"Epoch [{epoch+1:3d}/{NUM_EPOCHS}] | \"\n",
        "            f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:6.2f}% | \"\n",
        "            f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:6.2f}%\")"
      ],
      "metadata": {
        "id": "XoIA9DAr-zv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create plots\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Plot losses\n",
        "ax1.plot(train_losses, label=\"Training Loss\")\n",
        "ax1.plot(val_losses, label=\"Validation Loss\")\n",
        "ax1.set_xlabel(\"Epoch\")\n",
        "ax1.set_ylabel(\"Loss\")\n",
        "ax1.set_title(\"Training and Validation Loss\")\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot accuracies\n",
        "ax2.plot(train_accuracies, label=\"Training Accuracy\")\n",
        "ax2.plot(val_accuracies, label=\"Validation Accuracy\")\n",
        "ax2.set_xlabel(\"Epoch\")\n",
        "ax2.set_ylabel(\"Accuracy (%)\")\n",
        "ax2.set_title(\"Training and Validation Accuracy\")\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# Show plots\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GHnQ3cFc_jHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate the Model\n",
        "\n",
        "Once we're happy with the performance on the training and validation sets, it's time to test! We'll use our holdout (test) dataset to see how well the model performs. The good news is that we already have a `validation()` function; we just give it our trained model and test set."
      ],
      "metadata": {
        "id": "V_mj6kDmJ1xy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on our test set\n",
        "test_loss, test_accuracy = validate(model, test_loader, loss_fn, device)\n",
        "\n",
        "# Print out the results\n",
        "print(f\"Test Loss: {test_loss:.3f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}\")"
      ],
      "metadata": {
        "id": "pnimXvZ__tG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all predictions and true labels from test set\n",
        "all_predictions = []\n",
        "all_labels = []\n",
        "\n",
        "# Put model into evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Do not track gradients\n",
        "with torch.no_grad():\n",
        "\n",
        "    # Get batches of data from the test dataset loader\n",
        "    for batch_x, batch_y in test_loader:\n",
        "        batch_x = batch_x.to(device)\n",
        "        batch_y = batch_y.to(device)\n",
        "\n",
        "        # Get predicted classes (max value of outputs)\n",
        "        outputs = model(batch_x)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        # Move predictions and labels to CPU\n",
        "        all_predictions.extend(predicted.cpu())\n",
        "        all_labels.extend(batch_y.cpu())\n",
        "\n",
        "# Convert predictions and labels to NumPy arrays\n",
        "all_predictions = np.array(all_predictions)\n",
        "all_labels = np.array(all_labels)"
      ],
      "metadata": {
        "id": "JupG-zPWKUZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an empty array for our confusion matrix\n",
        "num_classes = len(class_names)\n",
        "conf_matrix = np.zeros((num_classes, num_classes), dtype=int)\n",
        "\n",
        "# Add the stats to the confusion matrix\n",
        "for true_label, pred_label in zip(all_labels, all_predictions):\n",
        "    conf_matrix[true_label, pred_label] += 1\n",
        "\n",
        "# Print header\n",
        "print(\"Confusion Matrix:\")\n",
        "print(f\"{'True\\\\Pred':<12}\", end=\"\")\n",
        "for class_name in class_names:\n",
        "    print(f\"{class_name:>12}\", end=\"\")\n",
        "print()\n",
        "\n",
        "# Print matrix with row labels\n",
        "for i, class_name in enumerate(class_names):\n",
        "    print(f\"{class_name:<12}\", end=\"\")\n",
        "    for j in range(num_classes):\n",
        "        print(f\"{conf_matrix[i, j]:>12}\", end=\"\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "G25qyq5YKrbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate per-class accuracy\n",
        "print(\"\\nPer-Class Performance:\")\n",
        "print(f\"  {'Class':<15} {'Correct':<10} {'Total':<10} {'Accuracy':<10}\")\n",
        "print(f\"  {'-'*45}\")\n",
        "\n",
        "# Print per-class accuracies\n",
        "for i, class_name in enumerate(class_names):\n",
        "    correct = conf_matrix[i, i]  # Diagonal elements\n",
        "    total = conf_matrix[i, :].sum()  # Sum of row\n",
        "    accuracy = 100 * correct / total if total > 0 else 0\n",
        "    print(f\"  {class_name:<15} {correct:<10} {total:<10} {accuracy:>6.2f}%\")"
      ],
      "metadata": {
        "id": "SCyEZg1TOULw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print header\n",
        "print(\"Metrics per Class:\")\n",
        "print(f\"  {'Class':<15} {'Precision':<12} {'Recall':<12} {'F1-Score':<12}\")\n",
        "print(f\"  {'-'*51}\")\n",
        "\n",
        "# Calculate per-class metrics\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "for i, class_name in enumerate(class_names):\n",
        "    # True Positives\n",
        "    tp = conf_matrix[i, i]\n",
        "\n",
        "    # False Positives\n",
        "    fp = conf_matrix[:, i].sum() - tp\n",
        "\n",
        "    # False Negatives\n",
        "    fn = conf_matrix[i, :].sum() - tp\n",
        "\n",
        "    # Precision: TP / (TP + FP)\n",
        "    if (tp + fp) > 0:\n",
        "        precision = tp / (tp + fp)\n",
        "    else:\n",
        "        precision = 0\n",
        "\n",
        "    # Recall: TP / (TP + FN)\n",
        "    if (tp + fn) > 0:\n",
        "        recall = tp / (tp + fn)\n",
        "    else:\n",
        "        recall = 0\n",
        "\n",
        "    # F1 score: single metric that combines precision (accuracy of\n",
        "    # positive predictions) and recall (completeness)\n",
        "    if (precision + recall) > 0:\n",
        "        f1 = 2 * (precision * recall) / (precision + recall)\n",
        "    else:\n",
        "        f1 = 0\n",
        "\n",
        "    # Store metrics\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "    # Print class metrics\n",
        "    print(f\"  {class_name:<15} {precision:>10.4f}  {recall:>10.4f}  {f1:>10.4f}\")\n",
        "\n",
        "# Calculate simple macro average across all classes\n",
        "macro_precision = np.mean(precisions)\n",
        "macro_recall = np.mean(recalls)\n",
        "macro_f1 = np.mean(f1_scores)\n",
        "\n",
        "# Print overall (average) metrics\n",
        "print(f\"  {'-'*51}\")\n",
        "print(f\"  {'Macro Avg':<15} {macro_precision:>10.4f}  {macro_recall:>10.4f}  {macro_f1:>10.4f}\")\n",
        "\n",
        "# Calculate overall accuracy\n",
        "overall_accuracy = np.trace(conf_matrix) / conf_matrix.sum() * 100\n",
        "print(f\"\\n  {'Overall Accuracy':<15} {overall_accuracy:>6.2f}%\")"
      ],
      "metadata": {
        "id": "DOCTEimXO5FK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Single Sample Inference\n",
        "\n",
        "At this point, we have a fully trained and evaluated model. If you were writing a paper on some new model architecture or application, you could probably stop here and write up your findings. But when it comes to deploying our model to an embedded system, we're not done!\n",
        "\n",
        "The next step is to demonstrate how the model performs inference on a single sample, which mimics how it will operate on an embedded device. During deployment, the model will receive one gesture at a time (not batches), so it's important to understand this single-sample inference process. This is also a good time to manually inspect how well the model performs on individual test samples and see the probability scores it assigns to each class.\n",
        "\n",
        "Note that we'll demonstrate simple inference without softmax (using raw logits) and with softmax. Softmax is computationally expensive on embedded devices, so you can often leave it out for simple classification tasks. Just perform `argmax(logits)` to get the predicted class! Only add softmax if you need calibrated probability scores (e.g. selecting a class based on a confidence threshold)."
      ],
      "metadata": {
        "id": "a40rffKURwL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose an index (in the training set)\n",
        "idx = 0\n",
        "\n",
        "# Get a sample\n",
        "x, y = test_dataset[idx]\n",
        "\n",
        "# Disable training features\n",
        "model.eval()\n",
        "\n",
        "# Add a batch dimension (the model expects it even if batch=1)\n",
        "x_batch = x.unsqueeze(0)\n",
        "print(f\"Sample shape: {x_batch.shape}\")\n",
        "\n",
        "# Move data to the same device as the model\n",
        "x_batch = x_batch.to(device)\n",
        "\n",
        "# Run inference (no gradient tracking)\n",
        "with torch.no_grad():\n",
        "    output = model(x_batch)\n",
        "\n",
        "# Show inference results\n",
        "print(f\"Ground truth label: {y} (Class: {class_names[y]})\")\n",
        "print(f\"Raw output (logits): {output[0].cpu().numpy()}\")\n",
        "print(f\"Predicted class: {torch.argmax(output[0]).item()}\")"
      ],
      "metadata": {
        "id": "ThjBxJOgPSYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply softmax to convert logits to probabilities\n",
        "probabilities = torch.softmax(output, dim=1)\n",
        "\n",
        "# Remove batch dimension and convert to NumPy array on CPU\n",
        "probabilities = probabilities[0].cpu().numpy()\n",
        "\n",
        "print(f\"Class probabilities:\")\n",
        "for i, class_name in enumerate(class_names):\n",
        "    prob = probabilities[i] * 100\n",
        "    print(f\"  {class_name:12s}: {prob:5.2f}%\")"
      ],
      "metadata": {
        "id": "XAfPshZLTgxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export Model\n",
        "\n",
        "At this point, we're ready to export our model to deploy to the target device. We'll use the Open Neural Network Exchange (ONNX) format, as it is commonly accepted on many frameworks and platforms.\n",
        "\n",
        "> Note: If you would like to perform inference using the ONNX model directly on a CPU or GPU-based system (e.g. laptop, server, smartphone), check out [ONNX Runtime](https://onnxruntime.ai/).\n",
        "\n",
        "PyTorch has a built-in exporter. It requires you to feed some dummy input into the model (this can be random values with the expected input shape), and it will trace the data as it flows through the network in order to construct the ONNX model.\n",
        "\n",
        "We will also need to provide the ONNX *opset version*. This defines a versioned set of operators that the model can use during a forward pass. The opset you export with must be supported by both the ONNX specification and your target compiler/runtime (e.g., RUHMI/Ethos-U). You can get a list of operators and which versions support them [here](https://github.com/microsoft/onnxruntime/blob/main/docs/OperatorKernels.md).\n",
        "\n",
        "Note that in most cases, the export process will produce 2 separate files:\n",
        "* **.onnx** - Model architecture and metadata (with references to external weight data)\n",
        "* **.onnx.data** - Model weights (external data file)\n",
        "\n",
        "The two files must be kept together in the same directory whenever you download them, load them in tools like Netron, or deploy them to a runtime environment."
      ],
      "metadata": {
        "id": "A7NaMILTW8Ro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Put the model into evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Create a dummy input tensor with the same shape as one sample (batch=1)\n",
        "dummy_input = torch.randn(1, input_size).to(device)\n",
        "\n",
        "# Export to ONNX\n",
        "torch.onnx.export(\n",
        "    model,                              # Model to export\n",
        "    dummy_input,                        # Example input (for tracing)\n",
        "    ONNX_PATH,                          # Output file path\n",
        "    export_params=True,                 # Export with trained weights\n",
        "    opset_version=ONNX_OPSET_VERSION,   # Which operations are supported\n",
        "    do_constant_folding=True,           # Optimize constant operations\n",
        "    input_names=['input'],              # Name for input layer\n",
        "    output_names=['output']             # Name for output layer\n",
        ")\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "id": "XUToWoVjT9-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export Calibration Data\n",
        "\n",
        "RUHMI needs calibration data to determine the optimal scale and zero-point for converting your float32 weights and activations to int8. By observing real data flowing through the network, it learns which value ranges actually matter and allocates the limited 8-bit precision accordingly. This prevents accuracy loss that would occur from blind quantization without understanding your data distribution.\n",
        "\n",
        "After executing this cell, download the **.npz** file."
      ],
      "metadata": {
        "id": "UxOYCsc4kQ8O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Don't exceed the total number of available samples\n",
        "num_samples = min(NUM_CALIB_SAMPLES, len(val_dataset))\n",
        "\n",
        "# Randomly choose from validation set, even if it's already randomized\n",
        "indices = random.sample(range(len(val_dataset)), num_samples)\n",
        "\n",
        "# Get samples (ignore the labels) and convert to NumPy arrays\n",
        "calib_samples = []\n",
        "for i in range(num_samples):\n",
        "    x, _ = val_dataset[i]\n",
        "    calib_samples.append(x.numpy())\n",
        "\n",
        "# Stack into a single array: shape (num_samples, input_size)\n",
        "calib_data = np.stack(calib_samples, axis=0)\n",
        "\n",
        "# Save samples as NPZ\n",
        "np.savez(CALIB_NPZ_PATH, input=calib_data)\n",
        "print(f\"Calibration data shape: {calib_data.shape}\")\n",
        "print(f\"Saved calibration data to: {CALIB_NPZ_PATH}\")"
      ],
      "metadata": {
        "id": "oCKnN2L0kis9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Helper Code\n",
        "\n",
        "We're going to generate some C code that we can copy directly into our embedded program to help with the data preprocessing step. Remember how we standardized our training data? Well, we need to do the exact same thing to any new data we capture before feeding it to the model. That includes using the same per-channel values for mean and standard deviation that we calculated from the training set!\n",
        "\n",
        "Note that this is a simple example, as we'll write our preprocessing functions manually in C. You can get very creative here if you'd like: for example, having Python generate all the required preprocessing functions for you."
      ],
      "metadata": {
        "id": "Ut2VTzEkfCWj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "xTMp4LfKmYNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c_code = f\"\"\"\\\n",
        "// Sensor channels: {', '.join(channel_names)}\n",
        "#define NUM_CHANNELS {len(channel_names)}\n",
        "\n",
        "// Mean for each sensor channel\n",
        "const float STANDARDIZATION_MEANS[NUM_CHANNELS] = {{\n",
        "    {', '.join([f'{m:.6f}f' for m in means])}\n",
        "}};\n",
        "\n",
        "// Standard deviation for each sensor channel\n",
        "const float STANDARDIZATION_STD_DEVS[NUM_CHANNELS] = {{\n",
        "    {', '.join([f'{s:.6f}f' for s in stds])}\n",
        "}};\n",
        "\"\"\"\n",
        "print(c_code)\n"
      ],
      "metadata": {
        "id": "fOxV7wWkau3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deploy!\n",
        "\n",
        "At this point, you have everything you need to deploy your model to your embedded device. Download the *model.onnx* and *model.onnx.data* files. Use your vendor's toolset (e.g. Renesas RUHMI, LiteRT) to quantize, compress, and compile the model for your target device.\n",
        "\n",
        "If you'd like to visualize your model, I recommend opening the *model.onnx* file in the [netron.app](https://netron.app/) viewer. This is a great way to see how the layers are connected and how data flows through the model.\n",
        "\n",
        "You will also want to copy the generated C code (standardization values) to your program so that you can preprocess your data. Remember: anything you did to transform or modify your training data prior to feeding it to your model will have to be done prior to inference! This includes standardizing each sensor channel using the exact mean and standard deviation values from the training set."
      ],
      "metadata": {
        "id": "IQqTrzQHiIlj"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}